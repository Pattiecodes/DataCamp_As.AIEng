{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1us5Qv+vwJ8i+MNjRma+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pattiecodes/DataCamp_As.AIEng/blob/main/Module_12_Introduction_to_Testing_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module Start ---"
      ],
      "metadata": {
        "id": "vr0x7BKUHJZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The first test suite\n",
        "In this exercise, you will write the first test suite that includes the types of tests that you have learned using the pytest library.\n",
        "\n",
        "The function multiple_of_two checks whether the num is a multiple of 2 or not. You will implement and run two regular assert tests.\n",
        "\n",
        "The pytest package has already been imported.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "Write an assert statement that is expected to be True."
      ],
      "metadata": {
        "id": "tzqO9zxHHNGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVcgGRqIEcEw"
      },
      "outputs": [],
      "source": [
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_numbers():\n",
        "    # Write the \"True\" test below\n",
        "    assert multiple_of_two(2) is True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "Write an assert statement that is expected to be False."
      ],
      "metadata": {
        "id": "mlUbPbI1HXmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_numbers():\n",
        "    assert multiple_of_two(2) is True\n",
        "    # Write the \"False\" test below\n",
        "    assert multiple_of_two(3) is False"
      ],
      "metadata": {
        "id": "2OyA7gpcHYm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytest.raises\n",
        "In this exercise, you will continue writing the first test suite using the pytest library.\n",
        "\n",
        "The function multiple_of_two checks whether the num is a multiple of 2 or not. In this exercise, you will implement a test that expects to raise an Exception.\n",
        "\n",
        "The pytest package has been imported.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Define a context manager for the exception test.\n",
        "Write a test to check that the zero input multiple_of_two(num=0) results in the ValueError exception."
      ],
      "metadata": {
        "id": "edCGGN45Hxre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_zero():\n",
        "  \t# Add a context for an exception test here\n",
        "    with pytest.raises(ValueError):\n",
        "      \t# Check zero input below\n",
        "        multiple_of_two(0)"
      ],
      "metadata": {
        "id": "DjoTUioAHx8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the test!\n",
        "Yay! Your pytest test suite is ready to be launched. Now you will enter a simple command to run the test suite you developed in the previous exercise. Let's run the tests via the command-line interface.\n",
        "\n",
        "A quick overview of the exercise: you can find the exercise instructions below this section, the run_the_test.py script on the right, and the terminal at the bottom (below the script).\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Add import of the pytest library to the code.\n",
        "Enter the pytest run_the_test.py command to CLI and press Enter.\n",
        "Press the \"Submit Answer\" button at the end."
      ],
      "metadata": {
        "id": "ZIHcZcrz1K2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest\n",
        "\n",
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_numbers():\n",
        "    assert multiple_of_two(2) is True\n",
        "    assert multiple_of_two(3) is False\n",
        "\n",
        "def test_zero():\n",
        "    with pytest.raises(ValueError):\n",
        "        multiple_of_two(0)\n"
      ],
      "metadata": {
        "id": "pRmNlY1G1LKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in CLI\n",
        "pytest run_the_test.py"
      ],
      "metadata": {
        "id": "e4VGeE231QCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with the keyword\n",
        "Sometimes you want to run only the tests with a certain name (assuming that the names of the tests are meaningful). In this exercise, you will practice running tests with keyword selection. To be accurate, you have to run only the tests containing the word \"numbers\".\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Add import of the pytest library to the code.\n",
        "Execute the pytest command to run run_the_test.py, specifying the keywords as \"numbers\".\n",
        "Press Enter.\n",
        "Press the \"Submit Answer\" button at the end."
      ],
      "metadata": {
        "id": "FLEMtAfN1Q1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest\n",
        "\n",
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_numbers():\n",
        "    assert multiple_of_two(2) == True\n",
        "    assert multiple_of_two(3) == False\n",
        "\n",
        "def test_zero():\n",
        "    with pytest.raises(ValueError):\n",
        "        multiple_of_two(0)\n"
      ],
      "metadata": {
        "id": "dLHne--K1aIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in CLI\n",
        "pytest run_the_test.py -k \"numbers\""
      ],
      "metadata": {
        "id": "bbZGvmMI1cAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Failed tests with xfail\n",
        "In this exercise, you will use pytest markers for the first time in order to specify the behavior of the test. You have already seen the function multiple_of_two, which checks whether the num is a multiple of 2 or not. The pytest library was already imported for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Add the correct pytest marker for a test that is expected to fail.\n",
        "Write any assert test that is expected to fail."
      ],
      "metadata": {
        "id": "vtaY2BNRsRne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "# Add the pytest marker decorator here\n",
        "@pytest.mark.xfail\n",
        "def test_fails():\n",
        "    # Write any assert test that will fail\n",
        "    assert multiple_of_two('2 * 2 == 5') is True"
      ],
      "metadata": {
        "id": "lm1_UFsMsR9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional skipping\n",
        "Sometimes, you want to skip a test if some condition is met. For example, you want to conduct a test unless today is Saturday. In this case, you can use the datetime library for getting the current day of the week and the pytest marker for conditional skipping the test function. To pass a condition to the conditional skipping pytest marker, you can use @pytest.mark.skipif(condition) The pytest library was already imported for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Add the \"conditional skip\" decorator to make it work.\n",
        "Add the condition_string into the decorator call.\n",
        "Complete the assertion tests."
      ],
      "metadata": {
        "id": "14qoiC-9s34K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week = datetime.now().isoweekday()\n",
        "\n",
        "def get_unique_values(lst):\n",
        "    return list(set(lst))\n",
        "\n",
        "condition_string = 'day_of_week == 6'\n",
        "# Add the conditional skip marker and the string here\n",
        "@pytest.mark.skipif(condition_string)\n",
        "def test_function():\n",
        "\t# Complete the assertion tests here\n",
        "    assert get_unique_values([1,2,3]) == [1,2,3]\n",
        "    assert get_unique_values([1,2,3,1]) == [1,2,3]"
      ],
      "metadata": {
        "id": "u7NymW6Os4a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n",
        "In this exercise you will create a fixture and finish test functions. Here, you have a simple data pipeline and some tests to check the data it returns. Since the tests goal is to check that the data is correct, it would be convenient to implement the pipeline as a fixture.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Start with importing the pytest package."
      ],
      "metadata": {
        "id": "fLTE-Hl0mSJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest"
      ],
      "metadata": {
        "id": "i3iNEw91mSa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "3\n",
        "Declare the fixture decorator.\n",
        "Give your fixture function the name prepare_data()."
      ],
      "metadata": {
        "id": "n0Fhpj9GmbuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest\n",
        "\n",
        "# --- Added code ---\n",
        "# Define the fixture decorator\n",
        "@pytest.fixture\n",
        "# Name the fixture function\n",
        "def prepare_data():\n",
        "    return [i for i in range(10)]"
      ],
      "metadata": {
        "id": "hpQTdQxCmb8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3 Pass the prepare_data() to the test function.\n",
        "Create a test to ensure that prepare_data() contains 9 and does not contain 10."
      ],
      "metadata": {
        "id": "1CNF537Ymqo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest\n",
        "\n",
        "# Define the fixture decorator\n",
        "@pytest.fixture\n",
        "# Name the fixture function\n",
        "def prepare_data():\n",
        "    return [i for i in range(10)]\n",
        "\n",
        "# Create the tests\n",
        "def test_elements(prepare_data):\n",
        "    assert 9 in prepare_data\n",
        "    assert 10 not in prepare_data"
      ],
      "metadata": {
        "id": "AhS9A3jBmrFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with a fixture\n",
        "You will supplement the test that you made before with a fixture. It is really important that you run your tests after implementation, because that is the way to see the results.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Import the pytest library.\n",
        "Execute the CLI command to run the test from the terminal.\n",
        "Discover the output."
      ],
      "metadata": {
        "id": "wc-n9LUJniIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "@pytest.fixture\n",
        "def prepare_data():\n",
        "    return [i for i in range(10)]\n",
        "\n",
        "def test_elements(prepare_data):\n",
        "    assert 9 in prepare_data\n",
        "    assert 10 not in prepare_data"
      ],
      "metadata": {
        "id": "Fn4X5rk1njCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest run_with_fixtures.py"
      ],
      "metadata": {
        "id": "4xtohdfeno3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List with a custom length\n",
        "You already saw a list preparation implemented as a fixture. But what if you also want to customize the preparation process? For example, one might want to set a custom length for a generated list. You can implement it with chain fixture requests by making the \"length\" a separate fixture; let's call it list_length(). In the end, you will have a test function that requests the list, and the list is then generated by requesting the list_length().\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Define the list_length() fixture function for getting the length.\n",
        "Define the prepare_list() fixture function for list preparation.\n",
        "Pass list_length() to prepare_list().\n",
        "Run the test from CLI."
      ],
      "metadata": {
        "id": "zPKlONtznqvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "# Define the fixture for returning the length\n",
        "@pytest.fixture\n",
        "def list_length():\n",
        "    return 10\n",
        "\n",
        "# Define the fixture for a list preparation\n",
        "@pytest.fixture\n",
        "def prepare_list(list_length):\n",
        "    return [i for i in range(list_length)]\n",
        "\n",
        "def test_9(prepare_list):\n",
        "    assert 9 in prepare_list\n",
        "    assert 10 not in prepare_list\n"
      ],
      "metadata": {
        "id": "ksFc9sn1Ri8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest list_custom_len.py"
      ],
      "metadata": {
        "id": "wb13j0RxRpLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto add numbers\n",
        "Now you will practice declaring autouse. At the start, you have an empty Python list. And there is a function that adds some elements to it. Add autouse to the add_numbers_to_list() fixture function, so you could use it without explicitly requesting from the test function. And finally complete the assertion tests by checking if 1 is in init_list and if 9 is in init_list.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Declare the fixture decorator for the add_numbers_to_list() function.\n",
        "Apply autouse in the add_numbers_to_list() fixture.\n",
        "Complete the assertion tests.\n",
        "Run the test."
      ],
      "metadata": {
        "id": "fnLRBKpeCQ3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "@pytest.fixture\n",
        "def init_list():\n",
        "    return []\n",
        "\n",
        "# Declare the fixture with autouse\n",
        "@pytest.fixture(autouse=True)\n",
        "def add_numbers_to_list(init_list):\n",
        "    init_list.extend([i for i in range(10)])\n",
        "\n",
        "# Complete the tests\n",
        "def test_elements(init_list):\n",
        "    assert init_list(1)\n",
        "    assert init_list(9)\n",
        "\n",
        "# Code does not work. For @pytest.fixture purposes only"
      ],
      "metadata": {
        "id": "pRwXVirSCUaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest auto_add_numbers.py"
      ],
      "metadata": {
        "id": "s3Eln1TeCWzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data with teardown\n",
        "Teardowns help you to prevent memory leaks and other issues with the environment. In this exercise, you will implement a teardown for the prepare_data() function and run the test at the end.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Use the special keyword to return the data from the fixture.\n",
        "Clear the data list with the corresponding list method.\n",
        "Delete the data variable from the Python environment.\n",
        "Run the script using CLI."
      ],
      "metadata": {
        "id": "yHINVzWrjliG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "@pytest.fixture\n",
        "def prepare_data():\n",
        "    data = [i for i in range(10)]\n",
        "    # Return the data with the special keyword\n",
        "    yield data\n",
        "    # Clear the data list\n",
        "    data.clear()\n",
        "    # Delete the data variable\n",
        "    del data\n",
        "\n",
        "def test_elements(prepare_data):\n",
        "    assert 9 in prepare_data\n",
        "    assert 10 not in prepare_data\n"
      ],
      "metadata": {
        "id": "SvTCNFegjl1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "run data_w_teardown.py"
      ],
      "metadata": {
        "id": "v22QzRyHjo22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read data with teardown\n",
        "This time instead of a list, you will deal with a pandas.DataFrame of pandas package. You have the pytest fixture to read the data, and you have to implement the teardown to clean it up.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Use the special keyword to return df from the data fixture.\n",
        "Remove all rows from df with the drop method.\n",
        "Delete the df variable from the Python environment.\n",
        "Run the tests using CLI.\n",
        "\n"
      ],
      "metadata": {
        "id": "oNOYJaQ9kW_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "import pandas as pd\n",
        "\n",
        "@pytest.fixture\n",
        "def data():\n",
        "    df = pd.read_csv('/usr/local/share/games.csv')\n",
        "    # Return df with the special keyword\n",
        "    yield df\n",
        "    # Remove all rows in df\n",
        "    df.drop(df.index, inplace=True)\n",
        "    # Delete the df variable\n",
        "    del df\n",
        "\n",
        "def test_type(data):\n",
        "    assert type(data) == pd.DataFrame\n",
        "\n",
        "def test_shape(data):\n",
        "    assert data.shape[0] == 1512\n"
      ],
      "metadata": {
        "id": "Mq7IJHzdkXVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest read_df_teardown.py"
      ],
      "metadata": {
        "id": "Bcp5gkL-kZ6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Factorial of number\n",
        "You will implement pytest tests using the provided test cases to test the factorial function. The factorial function of n is the product of all positive integers less than or equal to n. It is guaranteed that n is a non-negative integer. At each step, you will get a test case that you need to implement in Python. The pytest library was already imported for you.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "Implement one test to check that for the input 5, the function returns 120."
      ],
      "metadata": {
        "id": "fNeAKdSVRPgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factorial(n):\n",
        "    if n == 0: return 1\n",
        "    elif (type(n) == int):\n",
        "        return n * factorial(n-1)\n",
        "    else: return -1\n",
        "\n",
        "# Test case: expected input\n",
        "def test_regular():\n",
        "\tassert factorial(5) == 120"
      ],
      "metadata": {
        "id": "-V6kItFwRPzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3 Implement a test to check that for the zero input 0, the function returns 1."
      ],
      "metadata": {
        "id": "sAxxPkT-RRez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factorial(n):\n",
        "    if n == 0: return 1\n",
        "    elif (type(n) == int):\n",
        "        return n * factorial(n-1)\n",
        "    else: return -1\n",
        "\n",
        "# Test case: zero input\n",
        "def test_zero():\n",
        "\tassert factorial(0) == 1"
      ],
      "metadata": {
        "id": "g5MO_tqORTxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "Implement a test to check that for the string input '5', the function returns -1."
      ],
      "metadata": {
        "id": "2t8hhR5CReZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factorial(n):\n",
        "    if n == 0: return 1\n",
        "    elif (type(n) == int):\n",
        "        return n * factorial(n-1)\n",
        "    else: return -1\n",
        "\n",
        "# Test case: input of a wrong type\n",
        "def test_str():\n",
        "    assert factorial('5') == -1\n",
        "    print('Test passed')\n",
        "\n",
        "test_str()"
      ],
      "metadata": {
        "id": "P6mTZKH-RgZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run factorial\n",
        "Now that you implemented the tests let's run them with pytest to see the results! As before, you might want to know how many tests passed and how many failed.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Run the test script with pytest CLI as before."
      ],
      "metadata": {
        "id": "VFEXgVJzSKzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in CLI\n",
        "pytest factorial.py"
      ],
      "metadata": {
        "id": "fId2yLGYSLGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregate with sum\n",
        "You will deal with an aggregation feature, agg_with_sum(). As you know, pd.DataFrame.groupby() returns a new dataset by aggregating the initial one with some function, in this case - .sum(). But the important thing is that you want to verify it works properly.\n",
        "\n",
        "Let's assume you know nothing about the data, but you know for sure that agg_with_sum() returns pd.Series. It is also reasonable to assume that the pd.Series will not be empty, and it will also contain some numeric values since it was processed with .sum().\n",
        "\n",
        "Instructions\n",
        "0XP\n",
        "Write a test to check that the type of aggregated is pd.Series.\n",
        "Write a test to check that the number of rows in aggregated is more than 0.\n",
        "Write a test to check that the data type of aggregated is either int or float.\n",
        "Run the tests with CLI!"
      ],
      "metadata": {
        "id": "D8OIGTOPO6OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pytest\n",
        "\n",
        "# Fixture to prepare the data\n",
        "@pytest.fixture\n",
        "def get_df():\n",
        "    return pd.read_csv('https://assets.datacamp.com/production/repositories/6253/datasets/757c6cb769f7effc5f5496050ea4d73e4586c2dd/laptops_train.csv')\n",
        "\n",
        "# Aggregation feature\n",
        "def agg_with_sum(data, group_by_column, aggregate_column):\n",
        "    return data.groupby(group_by_column)[aggregate_column].sum()\n",
        "\n",
        "# Test function\n",
        "def test_agg_feature(get_df):\n",
        "    # Aggregate preparation\n",
        "    aggregated = agg_with_sum(get_df, 'Manufacturer', 'Price')\n",
        "    # Test the type of the aggregated\n",
        "    assert type(aggregated) == pd.Series\n",
        "    # Test the number of rows of the aggregated\n",
        "    assert aggregated.shape[0] > 0\n",
        "    # Test the data type of the aggregated\n",
        "    assert aggregated.dtype in (int, float)\n"
      ],
      "metadata": {
        "id": "I-mDxWR3O6oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest agg_with_sum.py"
      ],
      "metadata": {
        "id": "4bRoqCHLPII7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the file\n",
        "When you want to read a table in the CSV format in Python, you might want to use pandas.read_csv(). You will implement two integration tests with pytest to check the result of pandas.read_csv(). Then, you will run the tests with the CLI command.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Implement a test to verify the type of the object returned from get_df equals pd.DataFrame.\n",
        "Implement a test to check that get_df has more than 0 rows.\n",
        "Run the test with the CLI command."
      ],
      "metadata": {
        "id": "xjx3HHgNpTSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pytest\n",
        "\n",
        "# Fixture to read the dataframe\n",
        "@pytest.fixture\n",
        "def get_df():\n",
        "    return pd.read_csv('https://assets.datacamp.com/production/repositories/6253/datasets/757c6cb769f7effc5f5496050ea4d73e4586c2dd/laptops_train.csv')\n",
        "\n",
        "# Integration test function\n",
        "def test_get_df(get_df):\n",
        "    # Check the type\n",
        "    assert type(get_df) == pd.DataFrame\n",
        "    # Check the number of rows\n",
        "    assert len(get_df) > 0\n"
      ],
      "metadata": {
        "id": "tcH4Y6LwpT1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest reading_test.py"
      ],
      "metadata": {
        "id": "t7qwgiGVpVc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding an element\n",
        "Using the right data structure can significantly increase the performance of your code. For example, if you want to find a certain element in the data, you might want to choose between list and set. In this exercise, you will implement performance tests with pytest to compare the speed of the in operator applied correspondingly to the two data structures: list and set. The pytest package has already been imported.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Pass benchmark as an argument into the test functions.\n",
        "Then call benchmark() in the test functions passing find() as the first argument."
      ],
      "metadata": {
        "id": "6dGdwV-1sAhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_list():\n",
        "    return [i for i in range(1000)]\n",
        "def create_set():\n",
        "    return set([i for i in range(1000)])\n",
        "def find(it, el=50):\n",
        "    return el in it\n",
        "\n",
        "# Write the performance test for a list\n",
        "def test_list(benchmark):\n",
        "    benchmark(find, it=create_list())\n",
        "\n",
        "# Write the performance test for a set\n",
        "def test_set(benchmark):\n",
        "    benchmark(find, it=create_set())"
      ],
      "metadata": {
        "id": "g5PNuzj1sA-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speed of loops\n",
        "Of course, set is better suited for searching elements. It is based on hashes, so you can expect constant complexity most of the time. But what about iterating over all the object's elements? Let's compare the speed of loop iteration over the elements of list and set with pytest and pytest-benchmark. The pytest package has already been imported.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Add @benchmark decorator before the functions starting with iterate_.\n",
        "Complete the loops in iterate_list and iterate_set."
      ],
      "metadata": {
        "id": "C3scamGfss4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_list(benchmark):\n",
        "\t# Add decorator here\n",
        "    @benchmark\n",
        "    def iterate_list():\n",
        "\t\t# Complete the loop here\n",
        "        for el in [i for i in range(1000)]:\n",
        "            pass\n",
        "\n",
        "def test_set(benchmark):\n",
        "\t# Add decorator here\n",
        "    @benchmark\n",
        "    def iterate_set():\n",
        "        # Complete the loop here\n",
        "        for el in {i for i in range(1000)}:\n",
        "            pass"
      ],
      "metadata": {
        "id": "sHR8Y1X5stQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Factorial with unittest\n",
        "In this exercise, you will start using unittest to create basic tests for the factorial function. Since the library uses an object-oriented approach, the functions will be implemented as methods of a unittest.TestCase class. The unittest package has already been imported.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "Use .assertEqual() to check that the factorial of 5 equals 120."
      ],
      "metadata": {
        "id": "VuwZanvzYBSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func_factorial(number):\n",
        "    if number < 0:\n",
        "        raise ValueError('Factorial is not defined for negative values')\n",
        "    factorial = 1\n",
        "    while number > 1:\n",
        "        factorial = factorial * number\n",
        "        number = number - 1\n",
        "    return factorial\n",
        "\n",
        "class TestFactorial(unittest.TestCase):\n",
        "    def test_positives(self):\n",
        "        # Add the test for testing positives here\n",
        "        self.assertEqual(func_factorial(5), 120)"
      ],
      "metadata": {
        "id": "pQum9ayBYBh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "\n",
        "Use .assertEqual() to check that the factorial of 0 equals 1."
      ],
      "metadata": {
        "id": "US8GdGCmYC-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func_factorial(number):\n",
        "    if number < 0:\n",
        "        raise ValueError('Factorial is not defined for negative values')\n",
        "    factorial = 1\n",
        "    while number > 1:\n",
        "        factorial = factorial * number\n",
        "        number = number - 1\n",
        "    return factorial\n",
        "\n",
        "class TestFactorial(unittest.TestCase):\n",
        "    def test_zero(self):\n",
        "        # Add the test for testing zero here\n",
        "        self.assertEqual(func_factorial(0), 1)"
      ],
      "metadata": {
        "id": "SvpJJaVaYFQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "Use .assertRaises() to create a test for checking that the factorial of a negative number will raise a ValueError."
      ],
      "metadata": {
        "id": "Emci01IlYMdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "def func_factorial(number):\n",
        "    if number < 0:\n",
        "        raise ValueError('Factorial is not defined for negative values')\n",
        "    factorial = 1\n",
        "    while number > 1:\n",
        "        factorial = factorial * number\n",
        "        number = number - 1\n",
        "    return factorial\n",
        "\n",
        "class TestFactorial(unittest.TestCase):\n",
        "    def test_negatives(self):\n",
        "      \t# Add the test for testing negatives here\n",
        "        with self.assertRaises(ValueError):\n",
        "            func_factorial(-1)"
      ],
      "metadata": {
        "id": "pXSy6RYkYPIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is prime or not\n",
        "A prime number can only be divided by itself and 1 without remainders. In this exercise, you will test the function the is_prime() with unittest. The function gets a number and returns True if it is prime and False if it is not. It uses the math package to calculate the square root of the number. The packages math and unittest were already imported for you.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "Implement a test to check that 17 is prime."
      ],
      "metadata": {
        "id": "_JSghnOsYpFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_prime(num):\n",
        "    if num == 1: return False\n",
        "    up_limit = int(math.sqrt(num)) + 1\n",
        "    for i in range(2, up_limit):\n",
        "        if num % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "class TestSuite(unittest.TestCase):\n",
        "    def test_is_prime(self):\n",
        "        # Check that 17 is prime\n",
        "        self.assertEqual(is_prime(17), True)"
      ],
      "metadata": {
        "id": "M0Hc3T1NYpXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "\n",
        "Implement a test to check that 6 is not prime."
      ],
      "metadata": {
        "id": "A7MFLTqUYqzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_prime(num):\n",
        "    if num == 1: return False\n",
        "    up_limit = int(math.sqrt(num)) + 1\n",
        "    for i in range(2, up_limit):\n",
        "        if num % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "class TestSuite(unittest.TestCase):\n",
        "    def test_is_prime(self):\n",
        "        # Check that 6 is not prime\n",
        "        self.assertEqual(is_prime(6), False)"
      ],
      "metadata": {
        "id": "KhJ9myGvYtdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "Implement a test to check that 1 is not prime."
      ],
      "metadata": {
        "id": "BPFv9-SBY1yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_prime(num):\n",
        "    if num == 1: return False\n",
        "    up_limit = int(math.sqrt(num)) + 1\n",
        "    for i in range(2, up_limit):\n",
        "        if num % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "class TestSuite(unittest.TestCase):\n",
        "    def test_is_prime(self):\n",
        "        # Check that 1 is not prime\n",
        "        self.assertEqual(is_prime(1), False)"
      ],
      "metadata": {
        "id": "wQ8sJsqdY4EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run factorial with unittest\n",
        "You won't be able to find out anything before launching the tests. And you already have the test code. Now it is time to run your first test suite with unittest.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Use the terminal to test factorial_unittest.py with unittest from CLI."
      ],
      "metadata": {
        "id": "jnOXs7HsZphj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "python3 -m unittest factorial_unittest.py"
      ],
      "metadata": {
        "id": "fnOchBqcZpyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Erroneouos factorial\n",
        "It is very important not only to create tests but use them to find and fix errors. In this exercise, you will meet an error in the code and you will have to fix it.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Run the test script as is and see the error.\n",
        "Find the error in the code and fix it.\n",
        "Run the test script again to make sure that the problem was fixed."
      ],
      "metadata": {
        "id": "e-tkp13NauAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "def err_func_factorial(number):\n",
        "    if number < 0:\n",
        "        raise ValueError('Factorial is not defined for negative values')\n",
        "    factorial = 1\n",
        "    while number >= 2:\n",
        "        factorial = factorial * number\n",
        "        number = number - 1\n",
        "    return factorial\n",
        "\n",
        "class TestFactorial(unittest.TestCase):\n",
        "    def test_err_func_1(self):\n",
        "        self.assertEqual(err_func_factorial(3), 6)\n",
        "    def test_err_func_2(self):\n",
        "        self.assertEqual(err_func_factorial(4), 24)\n"
      ],
      "metadata": {
        "id": "oZPLYP8vauYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "python3 -m unittest err_factorial_unittest.py"
      ],
      "metadata": {
        "id": "_9VX-pcqav-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the string variable\n",
        "Now you will start using fixtures in unittest. This time, the prepared environment is the word 'banana'. Thus, the setup part is the word initialization, and the teardown part removes the variable.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Complete the .setUp() method by assigning 'banana' to the self.word variable.\n",
        "Create three tests to check that B and y are not in the list, and b is.\n",
        "Complete the .tearDown() method.\n",
        "Run the unittest test script from CLI."
      ],
      "metadata": {
        "id": "39tHFfq6CmF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestWord(unittest.TestCase):\n",
        "    # Fixture setup method\n",
        "    def setUp(self):\n",
        "        # Initialize the word banana here\n",
        "        self.word = 'banana'\n",
        "\n",
        "    # Test method\n",
        "    def test_the_word(self):\n",
        "        # Add the tests here\n",
        "        self.assertNotIn('B', self.word)\n",
        "        self.assertNotIn('y', self.word)\n",
        "        self.assertIn('b', self.word)\n",
        "\n",
        "    # Fixture teardown method\n",
        "    def tearDown(self):\n",
        "        # Delete the word variable here\n",
        "        del self.word"
      ],
      "metadata": {
        "id": "eCNR9lTzCmWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "python3 -m unittest palindrome_check.py"
      ],
      "metadata": {
        "id": "LYyjC5ahCnhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Palindrome check\n",
        "Palindrome is a word or phrase that reads the same backward as forward. The function create_data() returns some words, and the function check_palindrome() checks whether the word is a palindrome. You will complete the test suite's setup, test function, and teardown.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Initialize the self.data variable with create_data().\n",
        "Verify that self.data equals expected_result.\n",
        "Clear the self.data list.\n",
        "Run the test script with the CLI command."
      ],
      "metadata": {
        "id": "QzWmQZ8DG7xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "def check_palindrome(string):\n",
        "    reversed_string = string[::-1]\n",
        "    return string == reversed_string\n",
        "\n",
        "def create_data():\n",
        "    return ['level', 'step', 'peep', 'toot']\n",
        "\n",
        "class TestPalindrome(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        # Initialize data here\n",
        "        self.data = create_data()\n",
        "\n",
        "    def test_func(self):\n",
        "        expected_result = [True, False, True, True]\n",
        "        data_checked = list(map(check_palindrome, self.data))\n",
        "        # Verify the checked data here\n",
        "        self.assertEqual(data_checked, expected_result)\n",
        "\n",
        "    def tearDown(self):\n",
        "        # Clear the data here\n",
        "        self.data.clear()\n"
      ],
      "metadata": {
        "id": "nr7-Hcp-G8EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "python3 -m unittest palindrome_check.py"
      ],
      "metadata": {
        "id": "5WaRH6_5G9M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration and unit tests\n",
        "It is important to see when applying different testing types is appropriate. In this exercise, you will see them as a whole. You will create integration and unit tests with pytest for the data pipeline made with pandas. The pytest and pandas packages have already been imported.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Ensure that read_df has a pd.DataFrame type.\n",
        "Check that the data contains rows.\n",
        "Verify that the result does not contain nulls.\n",
        "Run pytest from CLI to see the results."
      ],
      "metadata": {
        "id": "srRwTYSuFLm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "import pandas as pd\n",
        "\n",
        "DF_PATH = \"/usr/local/share/salaries.csv\"\n",
        "\n",
        "@pytest.fixture\n",
        "def read_df():\n",
        "    # Read the CSV file from the path\n",
        "    return pd.read_csv(DF_PATH)\n",
        "def get_grouped(df):\n",
        "    # Group data by 'work_year' and calculate descriptive statistics for 'salary'\n",
        "    return df.groupby('work_year').agg({'salary': 'describe'})['salary']\n",
        "\n",
        "# Unit test for read_df\n",
        "def test_read_df(read_df):\n",
        "    # Check the type of the dataframe\n",
        "    assert isinstance(read_df, pd.DataFrame), \"The object is not a DataFrame\"\n",
        "    # Check that read_df contains rows\n",
        "    assert read_df.shape[0] > 0, \"The DataFrame has no rows\"\n",
        "\n",
        "# Integration test for grouping function\n",
        "def test_grouped(read_df):\n",
        "    df = read_df\n",
        "    salary_by_year = get_grouped(df)\n",
        "    # Check the nulls here\n",
        "    assert salary_by_year.isnull().sum().sum() == 0, \"The grouped result contains null values\"\n"
      ],
      "metadata": {
        "id": "jSLsawCzFL-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature and performance tests\n",
        "In this exercise, you will continue to test the pandas data pipeline. Here, you will create two types of tests. A feature test with pytest to validate that the feature \"finding a median salary for a 2022 year\" actually works. And a performance test with pytest-benchmark to find out how fast the process is with pytest-benchmark. Note: The function name testreadingspeed() in the solution is used to benchmark the performance. This is consistent with the naming convention and functionality.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Check that the resulting median has the float type.\n",
        "Check that the median salary is greater than 0.\n",
        "Define the test_reading_speed() function with the benchmark argument.\n",
        "Run pytest from CLI to see the results."
      ],
      "metadata": {
        "id": "1k-0_tAhFne5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "import pandas as pd\n",
        "\n",
        "DF_PATH = \"/usr/local/share/salaries.csv\"\n",
        "\n",
        "@pytest.fixture\n",
        "def read_df():\n",
        "    return pd.read_csv(DF_PATH)\n",
        "def get_grouped(df):\n",
        "    return df.groupby('work_year').agg({'salary': 'describe'})['salary']\n",
        "\n",
        "# Feature test for median salary in 2022\n",
        "def test_feature_2022(read_df):\n",
        "    salary_by_year = get_grouped(read_df)\n",
        "    salary_2022 = salary_by_year.loc[2022, '50%']\n",
        "    # Check the median type\n",
        "    assert isinstance(salary_2022, float), \"The median salary is not of type float\"\n",
        "    # Check the median is greater than zero\n",
        "    assert salary_2022 > 0, \"The median salary is not greater than zero\"\n",
        "\n",
        "# Performance test for reading the DataFrame\n",
        "def test_reading_speed(benchmark):\n",
        "    # Use benchmark to measure the speed of reading the DataFrame\n",
        "    result = benchmark(pd.read_csv, DF_PATH)\n",
        "    # Optionally, ensure the result is a DataFrame\n",
        "    assert isinstance(result, pd.DataFrame), \"The result is not a DataFrame\"\n"
      ],
      "metadata": {
        "id": "Vuqv0As3FnzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Energy pipeline\n",
        "You will work with the dataset that contains data about energy production by different countries. This pipeline groups the data by COUNTRY summing over VALUE, and then gets COUNTRY with the minimum VALUE. This time you will implement a unit test to make sure that the dataset does not contain nulls before getting the country with a minimum VALUE. And a feature test to make sure that the final result is str.\n",
        "\n",
        "Use the unittest framework.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Use unittest to verify that the dataset does not contain any nulls.\n",
        "Use unittest to ensure that the min_country() function returns a str.\n",
        "Run the unittest tests with CLI."
      ],
      "metadata": {
        "id": "G9DqRfCMGjsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "import pandas as pd\n",
        "DF_PATH = 'https://assets.datacamp.com/production/repositories/6253/datasets/f015ac99df614ada3ef5e011c168054ca369d23b/energy_truncated.csv'\n",
        "\n",
        "def get_data():\n",
        "    return pd.read_csv(DF_PATH)\n",
        "def min_country(df):\n",
        "    return df['VALUE'].idxmin()\n",
        "\n",
        "class TestDF(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.df = get_data()\n",
        "        self.df.drop('previousYearToDate', axis=1, inplace=True)\n",
        "        self.df = self.df.groupby('COUNTRY')\\\n",
        "            .agg({'VALUE': 'sum'})\n",
        "    def test_NAs(self):\n",
        "        # Check the number of nulls\n",
        "        self.assertEqual(self.df.isna().sum().sum(), 0)\n",
        "    def test_argmax(self):\n",
        "        # Check that min_country returns a string\n",
        "        self.assertIsInstance(min_country(self.df), str)\n",
        "    def tearDown(self):\n",
        "        self.df.drop(self.df.index, inplace=True)\n"
      ],
      "metadata": {
        "id": "xoN-Kk0XGkIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "python3 -m unittest energy_pipeline.py"
      ],
      "metadata": {
        "id": "IRlcfLA9GujH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module End ---"
      ],
      "metadata": {
        "id": "gr3HujG7GxdC"
      }
    }
  ]
}