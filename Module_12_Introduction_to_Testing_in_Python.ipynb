{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfSOqFt2jCL1OwNXJ8EgYR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pattiecodes/DataCamp_As.AIEng/blob/main/Module_12_Introduction_to_Testing_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module Start ---"
      ],
      "metadata": {
        "id": "vr0x7BKUHJZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The first test suite\n",
        "In this exercise, you will write the first test suite that includes the types of tests that you have learned using the pytest library.\n",
        "\n",
        "The function multiple_of_two checks whether the num is a multiple of 2 or not. You will implement and run two regular assert tests.\n",
        "\n",
        "The pytest package has already been imported.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "Write an assert statement that is expected to be True."
      ],
      "metadata": {
        "id": "tzqO9zxHHNGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVcgGRqIEcEw"
      },
      "outputs": [],
      "source": [
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_numbers():\n",
        "    # Write the \"True\" test below\n",
        "    assert multiple_of_two(2) is True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "Write an assert statement that is expected to be False."
      ],
      "metadata": {
        "id": "mlUbPbI1HXmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_numbers():\n",
        "    assert multiple_of_two(2) is True\n",
        "    # Write the \"False\" test below\n",
        "    assert multiple_of_two(3) is False"
      ],
      "metadata": {
        "id": "2OyA7gpcHYm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytest.raises\n",
        "In this exercise, you will continue writing the first test suite using the pytest library.\n",
        "\n",
        "The function multiple_of_two checks whether the num is a multiple of 2 or not. In this exercise, you will implement a test that expects to raise an Exception.\n",
        "\n",
        "The pytest package has been imported.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Define a context manager for the exception test.\n",
        "Write a test to check that the zero input multiple_of_two(num=0) results in the ValueError exception."
      ],
      "metadata": {
        "id": "edCGGN45Hxre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_zero():\n",
        "  \t# Add a context for an exception test here\n",
        "    with pytest.raises(ValueError):\n",
        "      \t# Check zero input below\n",
        "        multiple_of_two(0)"
      ],
      "metadata": {
        "id": "DjoTUioAHx8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the test!\n",
        "Yay! Your pytest test suite is ready to be launched. Now you will enter a simple command to run the test suite you developed in the previous exercise. Let's run the tests via the command-line interface.\n",
        "\n",
        "A quick overview of the exercise: you can find the exercise instructions below this section, the run_the_test.py script on the right, and the terminal at the bottom (below the script).\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Add import of the pytest library to the code.\n",
        "Enter the pytest run_the_test.py command to CLI and press Enter.\n",
        "Press the \"Submit Answer\" button at the end."
      ],
      "metadata": {
        "id": "ZIHcZcrz1K2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest\n",
        "\n",
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_numbers():\n",
        "    assert multiple_of_two(2) is True\n",
        "    assert multiple_of_two(3) is False\n",
        "\n",
        "def test_zero():\n",
        "    with pytest.raises(ValueError):\n",
        "        multiple_of_two(0)\n"
      ],
      "metadata": {
        "id": "pRmNlY1G1LKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in CLI\n",
        "pytest run_the_test.py"
      ],
      "metadata": {
        "id": "e4VGeE231QCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with the keyword\n",
        "Sometimes you want to run only the tests with a certain name (assuming that the names of the tests are meaningful). In this exercise, you will practice running tests with keyword selection. To be accurate, you have to run only the tests containing the word \"numbers\".\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Add import of the pytest library to the code.\n",
        "Execute the pytest command to run run_the_test.py, specifying the keywords as \"numbers\".\n",
        "Press Enter.\n",
        "Press the \"Submit Answer\" button at the end."
      ],
      "metadata": {
        "id": "FLEMtAfN1Q1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest\n",
        "\n",
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "def test_numbers():\n",
        "    assert multiple_of_two(2) == True\n",
        "    assert multiple_of_two(3) == False\n",
        "\n",
        "def test_zero():\n",
        "    with pytest.raises(ValueError):\n",
        "        multiple_of_two(0)\n"
      ],
      "metadata": {
        "id": "dLHne--K1aIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in CLI\n",
        "pytest run_the_test.py -k \"numbers\""
      ],
      "metadata": {
        "id": "bbZGvmMI1cAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Failed tests with xfail\n",
        "In this exercise, you will use pytest markers for the first time in order to specify the behavior of the test. You have already seen the function multiple_of_two, which checks whether the num is a multiple of 2 or not. The pytest library was already imported for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Add the correct pytest marker for a test that is expected to fail.\n",
        "Write any assert test that is expected to fail."
      ],
      "metadata": {
        "id": "vtaY2BNRsRne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_of_two(num):\n",
        "    if num == 0:\n",
        "        raise(ValueError)\n",
        "    return num % 2 == 0\n",
        "\n",
        "# Add the pytest marker decorator here\n",
        "@pytest.mark.xfail\n",
        "def test_fails():\n",
        "    # Write any assert test that will fail\n",
        "    assert multiple_of_two('2 * 2 == 5') is True"
      ],
      "metadata": {
        "id": "lm1_UFsMsR9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional skipping\n",
        "Sometimes, you want to skip a test if some condition is met. For example, you want to conduct a test unless today is Saturday. In this case, you can use the datetime library for getting the current day of the week and the pytest marker for conditional skipping the test function. To pass a condition to the conditional skipping pytest marker, you can use @pytest.mark.skipif(condition) The pytest library was already imported for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Add the \"conditional skip\" decorator to make it work.\n",
        "Add the condition_string into the decorator call.\n",
        "Complete the assertion tests."
      ],
      "metadata": {
        "id": "14qoiC-9s34K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week = datetime.now().isoweekday()\n",
        "\n",
        "def get_unique_values(lst):\n",
        "    return list(set(lst))\n",
        "\n",
        "condition_string = 'day_of_week == 6'\n",
        "# Add the conditional skip marker and the string here\n",
        "@pytest.mark.skipif(condition_string)\n",
        "def test_function():\n",
        "\t# Complete the assertion tests here\n",
        "    assert get_unique_values([1,2,3]) == [1,2,3]\n",
        "    assert get_unique_values([1,2,3,1]) == [1,2,3]"
      ],
      "metadata": {
        "id": "u7NymW6Os4a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n",
        "In this exercise you will create a fixture and finish test functions. Here, you have a simple data pipeline and some tests to check the data it returns. Since the tests goal is to check that the data is correct, it would be convenient to implement the pipeline as a fixture.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Start with importing the pytest package."
      ],
      "metadata": {
        "id": "fLTE-Hl0mSJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest"
      ],
      "metadata": {
        "id": "i3iNEw91mSa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "3\n",
        "Declare the fixture decorator.\n",
        "Give your fixture function the name prepare_data()."
      ],
      "metadata": {
        "id": "n0Fhpj9GmbuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest\n",
        "\n",
        "# --- Added code ---\n",
        "# Define the fixture decorator\n",
        "@pytest.fixture\n",
        "# Name the fixture function\n",
        "def prepare_data():\n",
        "    return [i for i in range(10)]"
      ],
      "metadata": {
        "id": "hpQTdQxCmb8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3 Pass the prepare_data() to the test function.\n",
        "Create a test to ensure that prepare_data() contains 9 and does not contain 10."
      ],
      "metadata": {
        "id": "1CNF537Ymqo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pytest library\n",
        "import pytest\n",
        "\n",
        "# Define the fixture decorator\n",
        "@pytest.fixture\n",
        "# Name the fixture function\n",
        "def prepare_data():\n",
        "    return [i for i in range(10)]\n",
        "\n",
        "# Create the tests\n",
        "def test_elements(prepare_data):\n",
        "    assert 9 in prepare_data\n",
        "    assert 10 not in prepare_data"
      ],
      "metadata": {
        "id": "AhS9A3jBmrFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with a fixture\n",
        "You will supplement the test that you made before with a fixture. It is really important that you run your tests after implementation, because that is the way to see the results.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Import the pytest library.\n",
        "Execute the CLI command to run the test from the terminal.\n",
        "Discover the output."
      ],
      "metadata": {
        "id": "wc-n9LUJniIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "@pytest.fixture\n",
        "def prepare_data():\n",
        "    return [i for i in range(10)]\n",
        "\n",
        "def test_elements(prepare_data):\n",
        "    assert 9 in prepare_data\n",
        "    assert 10 not in prepare_data"
      ],
      "metadata": {
        "id": "Fn4X5rk1njCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest run_with_fixtures.py"
      ],
      "metadata": {
        "id": "4xtohdfeno3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List with a custom length\n",
        "You already saw a list preparation implemented as a fixture. But what if you also want to customize the preparation process? For example, one might want to set a custom length for a generated list. You can implement it with chain fixture requests by making the \"length\" a separate fixture; let's call it list_length(). In the end, you will have a test function that requests the list, and the list is then generated by requesting the list_length().\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Define the list_length() fixture function for getting the length.\n",
        "Define the prepare_list() fixture function for list preparation.\n",
        "Pass list_length() to prepare_list().\n",
        "Run the test from CLI."
      ],
      "metadata": {
        "id": "zPKlONtznqvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "# Define the fixture for returning the length\n",
        "@pytest.fixture\n",
        "def list_length():\n",
        "    return 10\n",
        "\n",
        "# Define the fixture for a list preparation\n",
        "@pytest.fixture\n",
        "def prepare_list(list_length):\n",
        "    return [i for i in range(list_length)]\n",
        "\n",
        "def test_9(prepare_list):\n",
        "    assert 9 in prepare_list\n",
        "    assert 10 not in prepare_list\n"
      ],
      "metadata": {
        "id": "ksFc9sn1Ri8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest list_custom_len.py"
      ],
      "metadata": {
        "id": "wb13j0RxRpLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto add numbers\n",
        "Now you will practice declaring autouse. At the start, you have an empty Python list. And there is a function that adds some elements to it. Add autouse to the add_numbers_to_list() fixture function, so you could use it without explicitly requesting from the test function. And finally complete the assertion tests by checking if 1 is in init_list and if 9 is in init_list.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Declare the fixture decorator for the add_numbers_to_list() function.\n",
        "Apply autouse in the add_numbers_to_list() fixture.\n",
        "Complete the assertion tests.\n",
        "Run the test."
      ],
      "metadata": {
        "id": "fnLRBKpeCQ3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "@pytest.fixture\n",
        "def init_list():\n",
        "    return []\n",
        "\n",
        "# Declare the fixture with autouse\n",
        "@pytest.fixture(autouse=True)\n",
        "def add_numbers_to_list(init_list):\n",
        "    init_list.extend([i for i in range(10)])\n",
        "\n",
        "# Complete the tests\n",
        "def test_elements(init_list):\n",
        "    assert init_list(1)\n",
        "    assert init_list(9)\n",
        "\n",
        "# Code does not work. For @pytest.fixture purposes only"
      ],
      "metadata": {
        "id": "pRwXVirSCUaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest auto_add_numbers.py"
      ],
      "metadata": {
        "id": "s3Eln1TeCWzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data with teardown\n",
        "Teardowns help you to prevent memory leaks and other issues with the environment. In this exercise, you will implement a teardown for the prepare_data() function and run the test at the end.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Use the special keyword to return the data from the fixture.\n",
        "Clear the data list with the corresponding list method.\n",
        "Delete the data variable from the Python environment.\n",
        "Run the script using CLI."
      ],
      "metadata": {
        "id": "yHINVzWrjliG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "@pytest.fixture\n",
        "def prepare_data():\n",
        "    data = [i for i in range(10)]\n",
        "    # Return the data with the special keyword\n",
        "    yield data\n",
        "    # Clear the data list\n",
        "    data.clear()\n",
        "    # Delete the data variable\n",
        "    del data\n",
        "\n",
        "def test_elements(prepare_data):\n",
        "    assert 9 in prepare_data\n",
        "    assert 10 not in prepare_data\n"
      ],
      "metadata": {
        "id": "SvTCNFegjl1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "run data_w_teardown.py"
      ],
      "metadata": {
        "id": "v22QzRyHjo22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read data with teardown\n",
        "This time instead of a list, you will deal with a pandas.DataFrame of pandas package. You have the pytest fixture to read the data, and you have to implement the teardown to clean it up.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Use the special keyword to return df from the data fixture.\n",
        "Remove all rows from df with the drop method.\n",
        "Delete the df variable from the Python environment.\n",
        "Run the tests using CLI.\n",
        "\n"
      ],
      "metadata": {
        "id": "oNOYJaQ9kW_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "import pandas as pd\n",
        "\n",
        "@pytest.fixture\n",
        "def data():\n",
        "    df = pd.read_csv('/usr/local/share/games.csv')\n",
        "    # Return df with the special keyword\n",
        "    yield df\n",
        "    # Remove all rows in df\n",
        "    df.drop(df.index, inplace=True)\n",
        "    # Delete the df variable\n",
        "    del df\n",
        "\n",
        "def test_type(data):\n",
        "    assert type(data) == pd.DataFrame\n",
        "\n",
        "def test_shape(data):\n",
        "    assert data.shape[0] == 1512\n"
      ],
      "metadata": {
        "id": "Mq7IJHzdkXVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest read_df_teardown.py"
      ],
      "metadata": {
        "id": "Bcp5gkL-kZ6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Factorial of number\n",
        "You will implement pytest tests using the provided test cases to test the factorial function. The factorial function of n is the product of all positive integers less than or equal to n. It is guaranteed that n is a non-negative integer. At each step, you will get a test case that you need to implement in Python. The pytest library was already imported for you.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "Implement one test to check that for the input 5, the function returns 120."
      ],
      "metadata": {
        "id": "fNeAKdSVRPgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factorial(n):\n",
        "    if n == 0: return 1\n",
        "    elif (type(n) == int):\n",
        "        return n * factorial(n-1)\n",
        "    else: return -1\n",
        "\n",
        "# Test case: expected input\n",
        "def test_regular():\n",
        "\tassert factorial(5) == 120"
      ],
      "metadata": {
        "id": "-V6kItFwRPzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3 Implement a test to check that for the zero input 0, the function returns 1."
      ],
      "metadata": {
        "id": "sAxxPkT-RRez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factorial(n):\n",
        "    if n == 0: return 1\n",
        "    elif (type(n) == int):\n",
        "        return n * factorial(n-1)\n",
        "    else: return -1\n",
        "\n",
        "# Test case: zero input\n",
        "def test_zero():\n",
        "\tassert factorial(0) == 1"
      ],
      "metadata": {
        "id": "g5MO_tqORTxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "Implement a test to check that for the string input '5', the function returns -1."
      ],
      "metadata": {
        "id": "2t8hhR5CReZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factorial(n):\n",
        "    if n == 0: return 1\n",
        "    elif (type(n) == int):\n",
        "        return n * factorial(n-1)\n",
        "    else: return -1\n",
        "\n",
        "# Test case: input of a wrong type\n",
        "def test_str():\n",
        "    assert factorial('5') == -1\n",
        "    print('Test passed')\n",
        "\n",
        "test_str()"
      ],
      "metadata": {
        "id": "P6mTZKH-RgZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run factorial\n",
        "Now that you implemented the tests let's run them with pytest to see the results! As before, you might want to know how many tests passed and how many failed.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Run the test script with pytest CLI as before."
      ],
      "metadata": {
        "id": "VFEXgVJzSKzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in CLI\n",
        "pytest factorial.py"
      ],
      "metadata": {
        "id": "fId2yLGYSLGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregate with sum\n",
        "You will deal with an aggregation feature, agg_with_sum(). As you know, pd.DataFrame.groupby() returns a new dataset by aggregating the initial one with some function, in this case - .sum(). But the important thing is that you want to verify it works properly.\n",
        "\n",
        "Let's assume you know nothing about the data, but you know for sure that agg_with_sum() returns pd.Series. It is also reasonable to assume that the pd.Series will not be empty, and it will also contain some numeric values since it was processed with .sum().\n",
        "\n",
        "Instructions\n",
        "0XP\n",
        "Write a test to check that the type of aggregated is pd.Series.\n",
        "Write a test to check that the number of rows in aggregated is more than 0.\n",
        "Write a test to check that the data type of aggregated is either int or float.\n",
        "Run the tests with CLI!"
      ],
      "metadata": {
        "id": "D8OIGTOPO6OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pytest\n",
        "\n",
        "# Fixture to prepare the data\n",
        "@pytest.fixture\n",
        "def get_df():\n",
        "    return pd.read_csv('https://assets.datacamp.com/production/repositories/6253/datasets/757c6cb769f7effc5f5496050ea4d73e4586c2dd/laptops_train.csv')\n",
        "\n",
        "# Aggregation feature\n",
        "def agg_with_sum(data, group_by_column, aggregate_column):\n",
        "    return data.groupby(group_by_column)[aggregate_column].sum()\n",
        "\n",
        "# Test function\n",
        "def test_agg_feature(get_df):\n",
        "    # Aggregate preparation\n",
        "    aggregated = agg_with_sum(get_df, 'Manufacturer', 'Price')\n",
        "    # Test the type of the aggregated\n",
        "    assert type(aggregated) == pd.Series\n",
        "    # Test the number of rows of the aggregated\n",
        "    assert aggregated.shape[0] > 0\n",
        "    # Test the data type of the aggregated\n",
        "    assert aggregated.dtype in (int, float)\n"
      ],
      "metadata": {
        "id": "I-mDxWR3O6oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest agg_with_sum.py"
      ],
      "metadata": {
        "id": "4bRoqCHLPII7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the file\n",
        "When you want to read a table in the CSV format in Python, you might want to use pandas.read_csv(). You will implement two integration tests with pytest to check the result of pandas.read_csv(). Then, you will run the tests with the CLI command.\n",
        "\n",
        "Instructions\n",
        "100XP\n",
        "Implement a test to verify the type of the object returned from get_df equals pd.DataFrame.\n",
        "Implement a test to check that get_df has more than 0 rows.\n",
        "Run the test with the CLI command."
      ],
      "metadata": {
        "id": "xjx3HHgNpTSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pytest\n",
        "\n",
        "# Fixture to read the dataframe\n",
        "@pytest.fixture\n",
        "def get_df():\n",
        "    return pd.read_csv('https://assets.datacamp.com/production/repositories/6253/datasets/757c6cb769f7effc5f5496050ea4d73e4586c2dd/laptops_train.csv')\n",
        "\n",
        "# Integration test function\n",
        "def test_get_df(get_df):\n",
        "    # Check the type\n",
        "    assert type(get_df) == pd.DataFrame\n",
        "    # Check the number of rows\n",
        "    assert len(get_df) > 0\n"
      ],
      "metadata": {
        "id": "tcH4Y6LwpT1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI\n",
        "pytest reading_test.py"
      ],
      "metadata": {
        "id": "t7qwgiGVpVc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding an element\n",
        "Using the right data structure can significantly increase the performance of your code. For example, if you want to find a certain element in the data, you might want to choose between list and set. In this exercise, you will implement performance tests with pytest to compare the speed of the in operator applied correspondingly to the two data structures: list and set. The pytest package has already been imported.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Pass benchmark as an argument into the test functions.\n",
        "Then call benchmark() in the test functions passing find() as the first argument."
      ],
      "metadata": {
        "id": "6dGdwV-1sAhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_list():\n",
        "    return [i for i in range(1000)]\n",
        "def create_set():\n",
        "    return set([i for i in range(1000)])\n",
        "def find(it, el=50):\n",
        "    return el in it\n",
        "\n",
        "# Write the performance test for a list\n",
        "def test_list(benchmark):\n",
        "    benchmark(find, it=create_list())\n",
        "\n",
        "# Write the performance test for a set\n",
        "def test_set(benchmark):\n",
        "    benchmark(find, it=create_set())"
      ],
      "metadata": {
        "id": "g5PNuzj1sA-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speed of loops\n",
        "Of course, set is better suited for searching elements. It is based on hashes, so you can expect constant complexity most of the time. But what about iterating over all the object's elements? Let's compare the speed of loop iteration over the elements of list and set with pytest and pytest-benchmark. The pytest package has already been imported.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Add @benchmark decorator before the functions starting with iterate_.\n",
        "Complete the loops in iterate_list and iterate_set."
      ],
      "metadata": {
        "id": "C3scamGfss4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_list(benchmark):\n",
        "\t# Add decorator here\n",
        "    @benchmark\n",
        "    def iterate_list():\n",
        "\t\t# Complete the loop here\n",
        "        for el in [i for i in range(1000)]:\n",
        "            pass\n",
        "\n",
        "def test_set(benchmark):\n",
        "\t# Add decorator here\n",
        "    @benchmark\n",
        "    def iterate_set():\n",
        "        # Complete the loop here\n",
        "        for el in {i for i in range(1000)}:\n",
        "            pass"
      ],
      "metadata": {
        "id": "sHR8Y1X5stQ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}